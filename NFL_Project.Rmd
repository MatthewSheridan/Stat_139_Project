---
title: "R Notebook"
author: "Alex Baker, James Kitch, Jackson Smith, Matthew Sheridan"
output: pdf_document
fig_width: 4 
fig_height: 3 
---

\textbf{Introduction:}

Our data comes from the nflfastR package, which contains accumulated play-by-play data from 1999 through 2021, with additional predictors beginning in 2006. We hope to create an efficient, streamlined model capable of predicting the score differential of an NFL game. Furthermore, we also want to be able to use what we gain from our models to help make insightful analyses and predictions in other scenarios. Some predictors will impact only one of these models while others will prove to be far more significant than widely recognized: it all depends on which refining method produces the most successful and significant model. 


While we will have some variables with relatively clear-cut relationships with score differential, our analysis will also focus on how more “strategic” variables relate to success. More turnovers in a game and more total yards should correlate strongly with score differential, but we are interested in variables that have a more unclear relationship with the final outcome. Are missed extra point attempts indicative of the team as a whole having a bad day? What about third down conversion rate? And quarterback hits? These are the kinds of interactions and trends we hope to expose in our model. By using metrics that are not generally used to predict game outcomes, we hope to find insight into predicting wins that are not conventionally expected.


\textbf{Data Cleaning, EDA:}

```{r, results='hide', echo=F, eval=F,warning=F}
install.packages("tidyverse", type = "binary")
install.packages("ggrepel", type = "binary")
install.packages("ggimage", type = "binary")
install.packages("nflfastR", type = "binary")
install.packages("dplyr", type = "binary")
install.packages("randomForest", type = "binary")
```

```{r, message=FALSE, warning=F, results='hide', echo=F}
library(tidyverse)
library(ggrepel)
library(ggimage)
library(nflfastR)
library(dplyr)
library(gridExtra)
library(randomForest)
options(scipen = 9999)
```

```{r, echo=F}
data17 <- load_pbp(2017)
data18 <- load_pbp(2018)
data19 <- load_pbp(2019)
data20 <- load_pbp(2020)
data21 <- load_pbp(2021)
#head(data1$game_id,100)

#unique(data1$game_id)
clean = function(data1){
  names = c("Game_id","Team_Name","Home","TFL", "QB_Hit", "Pass_Yrd","Rush_Yrd", "TD","FG_attempt","XP_missed","FG_missed","FUM","INT","Fourth_Dwn_Con","Third_Dwn_Con","Pen", "Score_Dif")
  
  df <- data.frame()
  
  for(i in unique(data1$game_id)) {
    temp <- subset(data1, game_id == i)
    for(j in c(temp$home_team[1], temp$away_team[1])) {
      to_add <- c(i, #Game id
                  j, #team name
                  1*(j==temp$home_team[1]), #team is home
                  sum(temp$tackled_for_loss[temp$defteam == j] == 1, na.rm=TRUE), #tackles for loss
                  sum(temp$qb_hit[temp$posteam == j] == 1, na.rm=TRUE), #how many times team's QB was hit
                  sum(temp$passing_yards[temp$posteam == j], na.rm=TRUE), #team passing yards
                  sum(temp$rushing_yards[temp$posteam == j], na.rm=TRUE), #team rushing yards
                  sum(temp$touchdown[temp$posteam == j], na.rm=TRUE), #team touchdowns
                  sum(temp$field_goal_attempt[temp$posteam == j], na.rm=TRUE), #team field goal attempts
                  sum(temp$extra_point_result[temp$posteam == j]=="failed" | 
                        temp$extra_point_result[temp$posteam == j]=="blocked", na.rm=TRUE), #exp missed
                  sum(temp$field_goal_result[temp$posteam == j]=="missed" | 
                        temp$field_goal_result[temp$posteam == j]=="blocked", na.rm=TRUE), #fg missed
                  sum(temp$fumble[temp$defteam == j], na.rm=TRUE), #number of fumbles
                  sum(temp$interception[temp$defteam == j], na.rm=TRUE), #number of interceptions
                  sum(temp$fourth_down_converted[temp$posteam == j], na.rm=TRUE), #4th down conversions
                  sum(temp$third_down_converted[temp$posteam == j], na.rm=TRUE), #3rd down conversions
                  sum(temp$penalty[temp$posteam == j & temp$penalty_team == j], na.rm=TRUE), #number of penalties
                  temp$result[1]*ifelse(j==temp$away_team[1], -1, 1) #score differential
                  )
      df <- rbind(df, to_add)
    }
  }
  
  colnames(df) = names
  
  df = df %>% 
  mutate_at(c("Home","TFL", "QB_Hit", "Pass_Yrd","Rush_Yrd", "TD","FG_attempt","XP_missed","FG_missed","FUM","INT","Fourth_Dwn_Con","Third_Dwn_Con","Pen", "Score_Dif"), as.numeric)
  return(df)
}


RMSE <- function(y.obs, y.pred){
  return(sqrt(mean((y.obs-y.pred)^2)))
}
```


Below, we graphed the distributions for a number of different potential predictors, as well as their relationship with the response variable of interest. Most predictors are slightly right-skewed, as they have a positive support and have a slight "bell" shape for the most common values but are stretched out by the few exceptional games where a team throws for 500 yards or rushes for 250 yards. However, it is mild right-skewness as it is not to the extent that log-transforming them would make the distributions more symmetric. For example, if we log-transform `Pass_Yrd` we actually find that the the resulting distribution is left-skewed, suggesting that the log transformation was actually too strong!

Furthermore, we can do a preliminary investigation of the relationships between some of the predictors and the outcome variable of score differential in 2019. Notably, we can see that the number of fumbles caused by a team is positively associated with score differential and that it is a relatively linear trend. The number of third down conversions is also positively associated with score differential, but this seems more complicated than a "simple" linear trend. Teams with a very large number (> 8) of third down conversions in a game appear to have a more negative score differential than teans with 5-7 third down conversions. This suggests that in future models investigating the effects of quadratic or higher order polynomial terms could be reasonable.

```{r, echo=F, message=F}
#DO EDA HERE
data_2017 = clean(data17)
data_2018 = clean(data18)
data_2019 = clean(data19)
data_2020 = clean(data20)
data_2021 = clean(data21)
data_2019_2 = data.frame(data_2019)
data_2018_2 = data.frame(data_2018)
data_2019_2$year <- 2019
data_2018_2$year <- 2018
data_2018_2019 <- rbind(data_2018_2, data_2019_2)


g.score <- ggplot(data_2019, aes(x=Score_Dif)) + 
  geom_histogram(binwidth =1, color="black", size=0.2) +
  ggtitle("Score Differential", subtitle="2019 NFL Games")

g.pass <- ggplot(data_2019, aes(x=Pass_Yrd)) + 
  geom_histogram(bins=30, color="black", size=0.2) +
  ggtitle("Total Passing Yards", subtitle="2019 NFL Games")

# ggplot(data_2018_2019, aes(x=Pass_Yrd, group=as.factor(year), fill=as.factor(year))) + 
#   geom_histogram(bins=30, color="black", size=0.2, position="identity", alpha=0.6) +
#   ggtitle("Total Passing Yards", subtitle="2018 and 2019 NFL Games")

g.rush <- ggplot(data_2019, aes(x=Rush_Yrd)) + 
  geom_histogram(bins=30, color="black", size=0.2) +
  ggtitle("Total Rushing Yards", subtitle="2019 NFL Games")

g.ps_rsh <- ggplot(data_2019, aes(x=Pass_Yrd, y=Rush_Yrd)) + 
  geom_point() +
  ggtitle("Relationship of Passing Yards to Rushing Yards", subtitle="2019 NFL Games")

g.fum_sc <- ggplot(data_2019, aes(x=FUM, y=Score_Dif)) + 
  geom_point() +
  stat_smooth(method="lm", se=F) +
  ggtitle("Number of Fumbles Caused to Score Difference", subtitle="2019 NFL Games")

g.3_sc <- ggplot(data_2019, aes(x=Third_Dwn_Con, y=Score_Dif)) + 
  geom_point() +
  stat_smooth(method="lm", se=F) +
  ggtitle("Third Down Conversions vs Score Difference", subtitle="2019 NFL Games")

g.pass_sc <- ggplot(data_2019, aes(x=Pass_Yrd, y=Score_Dif)) + 
  geom_point() +
  ggtitle("Relationship of Passing Yards to Score Difference", subtitle="2019 NFL Games")
g.3 <- ggplot(data_2019, aes(x=Third_Dwn_Con)) + 
  geom_histogram(bins=30, color="black", size=0.2) +
  ggtitle("Third Down Conversions", subtitle="2019 NFL Games")
g.4 <- ggplot(data_2019, aes(x=Fourth_Dwn_Con)) + 
  geom_histogram(bins=30, color="black", size=0.2) +
  ggtitle("Fourth Down Conversions", subtitle="2019 NFL Games")
g.qb <- ggplot(data_2019, aes(x=QB_Hit)) + 
  geom_histogram(bins=30, color="black", size=0.2) +
  ggtitle("QB Hits", subtitle="2019 NFL Games")
g.td <- ggplot(data_2019, aes(x=TD)) + 
  geom_histogram(bins=30, color="black", size=0.2) +
  ggtitle("TDs", subtitle="2019 NFL Games")

#gridExtra::grid.arrange(g.pass, g.rush, nrow=1)
gridExtra::grid.arrange(g.fum_sc, g.3_sc)
gridExtra::grid.arrange(g.pass, g.rush, g.3, g.4, g.qb, g.td, nrow=3)

```

\textbf{Initial Modeling:}

The code for initializing the models has been hidden for space constraints. The linear model was using all predictors, the stepwise model stepped from an intercept only model to all predictors, and the randomforest has not been tuned (YET) and uses all predictors, as well as the default parameters. We can see that the RMSE's are pretty close together for all the models, but the stepwise linear model seems to outperform all.

```{r, warning=F, echo=F}
lm1 = lm(Score_Dif~., data=data_2019[,seq(3, ncol(data_2019))])

RF1 = randomForest(Score_Dif~., data=data_2019[,seq(2, ncol(data_2019))])

step1 <- step(lm(Score_Dif~1, data=data_2019), scope=formula(lm1), direction="forward",trace=0)
```


```{r, echo=F}
rmse_2021 = c(RMSE(data_2021$Score_Dif, predict(lm1, newdata=data_2021)),
              RMSE(data_2021$Score_Dif, predict(step1, newdata=data_2021)),
              RMSE(data_2021$Score_Dif, predict(RF1, newdata=data_2021)))

rmse_2020 = c(RMSE(data_2020$Score_Dif, predict(lm1, newdata=data_2020)),
              RMSE(data_2020$Score_Dif, predict(step1, newdata=data_2020)),
              RMSE(data_2020$Score_Dif, predict(RF1, newdata=data_2020)))

rmse_2019 = c(RMSE(data_2019$Score_Dif, predict(lm1)),
              RMSE(data_2019$Score_Dif, predict(step1)),
              RMSE(data_2019$Score_Dif, predict(RF1)))

rmse_2018 = c(RMSE(data_2018$Score_Dif, predict(lm1, newdata=data_2018)),
              RMSE(data_2018$Score_Dif, predict(step1, newdata=data_2018)),
              RMSE(data_2018$Score_Dif, predict(RF1, newdata=data_2018)))

rmse_2017 = c(RMSE(data_2017$Score_Dif, predict(lm1, newdata=data_2017)),
              RMSE(data_2017$Score_Dif, predict(step1, newdata=data_2017)),
              RMSE(data_2017$Score_Dif, predict(RF1, newdata=data_2017)))

rmse = data.frame(rmse_2017, rmse_2018, rmse_2019, rmse_2020, rmse_2021, row.names = c("Linear", "Step", "RF1"))
rmse
```

\textbf{Conclusion:}

National Football League data provides a ripe opportunity for statistical analysis, especially when able to access play-by-play level data using the `nflfastR` package. While most variables have a slight right skew to them and only take on positive values, this did not present tremendous challenges for our models. Going forward, we're interested to continue investigating the impact of variables that provide a clear relationship towards "success" in a game--such as total passing yards or total rushing yards--as well as more "strategic" variables such as the number of third and fourth down conversions. Given the  violations of symmetric distributions in many of the predictors and the potential for non-linear relationships to arise, examining the performance and interpretations of Random Forest models will also be a focus in our analysis. 

